#!/usr/bin/env python3
"""
Script para testar performance da API com Redis + Uvicorn + Nginx
Otimizado para 1000+ usuÃ¡rios simultÃ¢neos
"""
import requests
import time
import concurrent.futures
import json
import statistics
from datetime import datetime

BASE_URL = "http://localhost"  # Nginx
API_BASE = "http://localhost/api"
TOKEN = None

def get_auth_token():
    """Obter token JWT para autenticaÃ§Ã£o"""
    global TOKEN
    if TOKEN:
        return TOKEN
    
    # Assumindo que existe um usuÃ¡rio de teste
    login_data = {
        "username": "admin",  # ou seu usuÃ¡rio de teste
        "password": "admin123"  # ou sua senha de teste
    }
    
    try:
        response = requests.post(f"{API_BASE}/token/", json=login_data, timeout=10)
        if response.status_code == 200:
            TOKEN = response.json()["access"]
            return TOKEN
        else:
            print(f"Erro ao obter token: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"Erro na requisiÃ§Ã£o de login: {e}")
        return None

def make_request(endpoint, headers, timeout=30):
    """Fazer uma requisiÃ§Ã£o para um endpoint"""
    start_time = time.time()
    try:
        response = requests.get(f"{API_BASE}{endpoint}", headers=headers, timeout=timeout)
        end_time = time.time()
        
        return {
            'endpoint': endpoint,
            'status_code': response.status_code,
            'response_time': end_time - start_time,
            'success': response.status_code == 200,
            'content_length': len(response.content) if response.content else 0
        }
    except requests.exceptions.Timeout:
        return {
            'endpoint': endpoint,
            'status_code': 0,
            'response_time': timeout,
            'success': False,
            'error': 'Timeout'
        }
    except Exception as e:
        return {
            'endpoint': endpoint,
            'status_code': 0,
            'response_time': 0,
            'success': False,
            'error': str(e)
        }

def test_performance(concurrent_users=100, requests_per_user=10, test_name="Teste"):
    """Testar performance com mÃºltiplos usuÃ¡rios simultÃ¢neos"""
    token = get_auth_token()
    if not token:
        print("âŒ NÃ£o foi possÃ­vel obter token de autenticaÃ§Ã£o")
        return
    
    headers = {"Authorization": f"Bearer {token}"}
    
    endpoints = [
        "/campanhas/listar/",
        "/campanhas/minhas/",
        "/campanhas/beneficiaria/",
    ]
    
    print(f"\nğŸš€ {test_name}")
    print(f"ğŸ‘¥ UsuÃ¡rios simultÃ¢neos: {concurrent_users}")
    print(f"ğŸ“Š Requests por usuÃ¡rio: {requests_per_user}")
    print(f"ğŸ”— Endpoints: {len(endpoints)}")
    print(f"ğŸ“ˆ Total de requests: {concurrent_users * requests_per_user * len(endpoints)}")
    
    all_requests = []
    for _ in range(concurrent_users):
        for _ in range(requests_per_user):
            for endpoint in endpoints:
                all_requests.append((endpoint, headers))
    
    start_time = time.time()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
        futures = [executor.submit(make_request, endpoint, headers) for endpoint, headers in all_requests]
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    
    end_time = time.time()
    total_time = end_time - start_time
    
    # AnÃ¡lise dos resultados
    successful_requests = [r for r in results if r['success']]
    failed_requests = [r for r in results if not r['success']]
    
    if successful_requests:
        response_times = [r['response_time'] for r in successful_requests]
        avg_response_time = statistics.mean(response_times)
        median_response_time = statistics.median(response_times)
        max_response_time = max(response_times)
        min_response_time = min(response_times)
        p95_response_time = statistics.quantiles(response_times, n=20)[18] if len(response_times) > 20 else max_response_time
    else:
        avg_response_time = median_response_time = max_response_time = min_response_time = p95_response_time = 0
    
    # Calcular throughput
    throughput = len(all_requests) / total_time if total_time > 0 else 0
    
    print(f"\nğŸ“Š RESULTADOS:")
    print(f"â±ï¸  Tempo total: {total_time:.2f}s")
    print(f"ğŸš€ Throughput: {throughput:.2f} requests/segundo")
    print(f"âœ… Requests bem-sucedidos: {len(successful_requests)}")
    print(f"âŒ Requests falharam: {len(failed_requests)}")
    print(f"ğŸ“ˆ Taxa de sucesso: {len(successful_requests) / len(all_requests) * 100:.1f}%")
    print(f"âš¡ Tempo de resposta mÃ©dio: {avg_response_time:.3f}s")
    print(f"ğŸ“Š Tempo de resposta mediano: {median_response_time:.3f}s")
    print(f"ğŸ“ˆ P95 tempo de resposta: {p95_response_time:.3f}s")
    print(f"ğŸ” Tempo de resposta mÃ¡ximo: {max_response_time:.3f}s")
    print(f"ğŸ”» Tempo de resposta mÃ­nimo: {min_response_time:.3f}s")
    
    # Verificar se estÃ¡ dentro dos parÃ¢metros esperados
    if throughput >= 500 and avg_response_time <= 0.1 and len(successful_requests) / len(all_requests) >= 0.95:
        print("ğŸ‰ âœ… PERFORMANCE EXCELENTE - Suporta 1000+ usuÃ¡rios!")
    elif throughput >= 200 and avg_response_time <= 0.2 and len(successful_requests) / len(all_requests) >= 0.90:
        print("ğŸ‘ âœ… PERFORMANCE BOA - Suporta 500+ usuÃ¡rios")
    elif throughput >= 100 and avg_response_time <= 0.5 and len(successful_requests) / len(all_requests) >= 0.80:
        print("âš ï¸  âš ï¸  PERFORMANCE REGULAR - Suporta 200+ usuÃ¡rios")
    else:
        print("âŒ âŒ PERFORMANCE RUIM - Precisa de otimizaÃ§Ãµes")
    
    return {
        'test_name': test_name,
        'concurrent_users': concurrent_users,
        'total_requests': len(all_requests),
        'successful_requests': len(successful_requests),
        'failed_requests': len(failed_requests),
        'success_rate': len(successful_requests) / len(all_requests) * 100,
        'total_time': total_time,
        'throughput': throughput,
        'avg_response_time': avg_response_time,
        'median_response_time': median_response_time,
        'p95_response_time': p95_response_time,
        'max_response_time': max_response_time,
        'min_response_time': min_response_time
    }

def test_cache_performance():
    """Testar performance do cache Redis"""
    print("\nğŸ§ª TESTE DE CACHE REDIS")
    print("=" * 50)
    
    token = get_auth_token()
    if not token:
        print("âŒ NÃ£o foi possÃ­vel obter token")
        return
    
    headers = {"Authorization": f"Bearer {token}"}
    endpoint = "/campanhas/listar/"
    
    # Primeira execuÃ§Ã£o (cache miss)
    print("ğŸ”„ Primeira execuÃ§Ã£o (cache miss)...")
    start_time = time.time()
    response1 = requests.get(f"{API_BASE}{endpoint}", headers=headers, timeout=30)
    time1 = time.time() - start_time
    
    # Segunda execuÃ§Ã£o (cache hit)
    print("âš¡ Segunda execuÃ§Ã£o (cache hit)...")
    start_time = time.time()
    response2 = requests.get(f"{API_BASE}{endpoint}", headers=headers, timeout=30)
    time2 = time.time() - start_time
    
    print(f"\nğŸ“Š RESULTADOS DO CACHE:")
    print(f"ğŸ”„ Cache miss: {time1:.3f}s")
    print(f"âš¡ Cache hit: {time2:.3f}s")
    print(f"ğŸš€ Melhoria: {time1/time2:.1f}x mais rÃ¡pido")
    
    if time2 < time1 * 0.5:
        print("âœ… Cache funcionando perfeitamente!")
    else:
        print("âš ï¸  Cache pode nÃ£o estar funcionando corretamente")

def main():
    """Executar todos os testes de performance"""
    print("ğŸ¯ TESTE DE PERFORMANCE - CONECTADES API")
    print("=" * 60)
    print(f"ğŸ• Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ”§ Arquitetura: Nginx + Redis + Uvicorn + Django")
    print("ğŸ¯ Objetivo: Suportar 1000+ usuÃ¡rios simultÃ¢neos")
    
    # Verificar se o servidor estÃ¡ rodando
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=5)
        if response.status_code == 200:
            print("âœ… Servidor estÃ¡ rodando")
        else:
            print("âš ï¸  Servidor pode nÃ£o estar funcionando corretamente")
    except:
        print("âŒ Servidor nÃ£o estÃ¡ acessÃ­vel. Execute: docker-compose up")
        return
    
    results = []
    
    # Teste de cache
    test_cache_performance()
    
    # Testes de carga progressivos
    test_configs = [
        (50, 5, "Teste Leve (50 usuÃ¡rios)"),
        (100, 10, "Teste MÃ©dio (100 usuÃ¡rios)"),
        (200, 10, "Teste Pesado (200 usuÃ¡rios)"),
        (500, 5, "Teste Extremo (500 usuÃ¡rios)"),
    ]
    
    for concurrent_users, requests_per_user, test_name in test_configs:
        try:
            result = test_performance(concurrent_users, requests_per_user, test_name)
            if result:
                results.append(result)
        except KeyboardInterrupt:
            print("\nâ¹ï¸  Teste interrompido pelo usuÃ¡rio")
            break
        except Exception as e:
            print(f"âŒ Erro no teste {test_name}: {e}")
    
    # Resumo final
    if results:
        print("\n" + "=" * 60)
        print("ğŸ“Š RESUMO FINAL DOS TESTES")
        print("=" * 60)
        
        for result in results:
            print(f"\nğŸ§ª {result['test_name']}:")
            print(f"   ğŸ‘¥ UsuÃ¡rios: {result['concurrent_users']}")
            print(f"   ğŸš€ Throughput: {result['throughput']:.1f} RPS")
            print(f"   âš¡ LatÃªncia mÃ©dia: {result['avg_response_time']:.3f}s")
            print(f"   ğŸ“ˆ Taxa de sucesso: {result['success_rate']:.1f}%")
    
    print(f"\nğŸ• Finalizado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()

